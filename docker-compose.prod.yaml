# Production Docker Compose Configuration
# Optimized for production deployment with security and performance considerations

services:
  # Reverse Proxy / Load Balancer
  nginx:
    image: nginx:alpine
    container_name: anineplus-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infra/nginx/ssl:/etc/ssl/certs:ro
      - nginx_cache:/var/cache/nginx
    depends_on:
      - gateway
      - core
    networks:
      - anineplus-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.2'

  # Application Services with Production Settings
  
  core:
    extends:
      file: docker-compose.yaml
      service: core
    environment:
      NODE_ENV: production
      LOG_LEVEL: info
      DATABASE_SSL: "true"
      REDIS_TLS: "true"
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  gateway:
    extends:
      file: docker-compose.yaml
      service: gateway
    environment:
      NODE_ENV: production
      LOG_LEVEL: info
      CORS_ORIGIN: "https://yourdomain.com"
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.3'
        reservations:
          memory: 256M
          cpus: '0.15'

  searcher:
    extends:
      file: docker-compose.yaml
      service: searcher
    environment:
      NODE_ENV: production
      LOG_LEVEL: info
      KAFKA_CONSUMER_GROUP_REBALANCE_TIMEOUT: 60000
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 512M
          cpus: '0.3'

  logger:
    extends:
      file: docker-compose.yaml
      service: logger
    environment:
      NODE_ENV: production
      LOG_LEVEL: warn
      LOG_RETENTION_DAYS: 30
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 256M
          cpus: '0.2'

  # Database with Production Optimizations
  core-database:
    extends:
      file: docker-compose.yaml
      service: core-database
    environment:
      POSTGRES_SHARED_PRELOAD_LIBRARIES: "pg_stat_statements"
      POSTGRES_MAX_CONNECTIONS: "200"
      POSTGRES_SHARED_BUFFERS: "256MB"
      POSTGRES_EFFECTIVE_CACHE_SIZE: "1GB"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./backups:/backups
      - ./infra/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./infra/postgres/init.sh:/docker-entrypoint-initdb.d/01-init.sh:ro
      - postgres_prod_logs:/var/log/postgresql
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Redis with Persistence and Clustering
  cache-service:
    extends:
      file: docker-compose.yaml
      service: cache-service
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 60
      --timeout 300
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Kafka with Production Settings
  kafka:
    extends:
      file: docker-compose.yaml
      service: kafka
    environment:
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Elasticsearch with Production Tuning
  elasticsearch:
    extends:
      file: docker-compose.yaml
      service: elasticsearch
    environment:
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - indices.memory.index_buffer_size=10%
      - indices.memory.min_index_buffer_size=48mb
      - indices.queries.cache.size=10%
      - indices.fielddata.cache.size=20%
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Monitoring Services
  
  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: anineplus-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infra/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - anineplus-network
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: anineplus-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/monitoring/grafana:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - anineplus-network
    restart: unless-stopped

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: anineplus-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - anineplus-network
    restart: unless-stopped

  # Backup Service
  db-backup:
    image: postgres:18-alpine
    container_name: anineplus-backup
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    environment:
      PGUSER: ${DB_USERNAME}
      PGPASSWORD: ${DB_PASSWORD}
      PGDATABASE: ${DB_DATABASE}
      PGHOST: core-database
    command: sh -c "chmod +x /backup.sh && /backup.sh"
    depends_on:
      - core-database
    networks:
      - anineplus-network
    restart: "no"
    profiles:
      - backup

volumes:
  # Production data volumes
  postgres_prod_data:
    driver: local
  postgres_prod_logs:
    driver: local
  nginx_cache:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  anineplus-network:
    external: true